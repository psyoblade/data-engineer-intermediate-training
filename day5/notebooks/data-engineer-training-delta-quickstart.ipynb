{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 델타 레이크 테이블 실습\n",
    "## 1.1 델타 레이크 의존성을 포함한 스파크 세션 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from IPython.display import display, display_pretty, clear_output, JSON\n",
    "\n",
    "from delta import *\n",
    "\n",
    "# 공통 데이터 위치\n",
    "home_jovyan = \"/home/jovyan\"\n",
    "work_data = f\"{home_jovyan}/work/data\"\n",
    "work_dir=!pwd\n",
    "work_dir = work_dir[0]\n",
    "warehouse_dir = f\"{work_dir}/spark-warehouse\"\n",
    "\n",
    "# Create spark session with hive enabled\n",
    "builder = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"pyspark-notebook\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Asia/Seoul\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\")\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_dir)\n",
    "    .enableHiveSupport()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 델타 레이크 생성시에 반드시 `configure_spark_with_delta_pip` 구성을 통해 실행되어야 정상적인 델타 의존성이 로딩됩니다\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://notebook:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-notebook</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f09f38e9c50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 노트북에서 테이블 형태로 데이터 프레임 출력을 위한 설정을 합니다\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # display enabled\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 100) # display output columns size\n",
    "\n",
    "# 로컬 환경 최적화\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5) # the number of partitions to use when shuffling data for joins or aggregations.\n",
    "spark.conf.set(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. 자주 사용하는 함수 등록 및 예제 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql(queries, num_rows = 20):\n",
    "    for query in queries.split(\";\"):\n",
    "        spark.sql(query).show(num_rows, truncate=False)\n",
    "\n",
    "def ls(command):\n",
    "    !ls -al {command}\n",
    "\n",
    "def cat(filename):\n",
    "    !cat {filename}\n",
    "\n",
    "def grep(keyword, filename):\n",
    "    !grep -i {keyword} {filename}\n",
    "\n",
    "def grep_and_json(keyword, filename):\n",
    "    !grep {keyword} {filename} | python -m json.tool\n",
    "\n",
    "def sql2(queries, num_rows = 20):\n",
    "    for query in queries.split(\";\"):\n",
    "        display(spark.sql(query).limit(num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- actors: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- votes: integer (nullable = true)\n",
      " |-- revenue: double (nullable = true)\n",
      " |-- metascore: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsv = (\n",
    "    spark.read\n",
    "    .option(\"delimiter\", \"\\t\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(\"imdb\")\n",
    ")\n",
    "tsv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n",
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|default  |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql(\"show databases\")\n",
    "sql(\"show tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.imdb_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|default  |\n",
      "+---------+\n",
      "\n",
      "+---------+----------+-----------+\n",
      "|namespace|tableName |isTemporary|\n",
      "+---------+----------+-----------+\n",
      "|default  |imdb_delta|false      |\n",
      "+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql(\"show databases\")\n",
    "sql(\"show tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------------------+---------+\n",
      "|rank|title                           |metascore|\n",
      "+----+--------------------------------+---------+\n",
      "|1   |Guardians of the Galaxy         |76       |\n",
      "|2   |Prometheus                      |65       |\n",
      "|13  |Rogue One                       |65       |\n",
      "|20  |Arrival                         |81       |\n",
      "|25  |Independence Day: Resurgence    |32       |\n",
      "|33  |X-Men: Apocalypse               |52       |\n",
      "|35  |Resident Evil: The Final Chapter|49       |\n",
      "|36  |Captain America: Civil War      |75       |\n",
      "|37  |Interstellar                    |74       |\n",
      "|49  |Star Trek Beyond                |68       |\n",
      "+----+--------------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql(\"\"\"\n",
    "select rank, title, metascore from imdb_delta where genre like '%Sci%' order by rank asc limit 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4. 장르별 빈도수를 계산하고 특정 장르 하나를 모두 삭제합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|year|cnt|\n",
      "+----+---+\n",
      "|2006|44 |\n",
      "|2007|53 |\n",
      "|2008|52 |\n",
      "|2009|51 |\n",
      "|2010|60 |\n",
      "|2011|63 |\n",
      "|2012|64 |\n",
      "|2013|91 |\n",
      "|2014|98 |\n",
      "|2015|127|\n",
      "|2016|297|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql(\"select year, count(1) as cnt from imdb_delta group by year order by year asc\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv.where(\"year = 2010\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|num_affected_rows|\n",
      "+-----------------+\n",
      "|60               |\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql(\"delete from imdb_delta where year = 2010\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|year|cnt|\n",
      "+----+---+\n",
      "|2006|44 |\n",
      "|2007|53 |\n",
      "|2008|52 |\n",
      "|2009|51 |\n",
      "|2011|63 |\n",
      "|2012|64 |\n",
      "|2013|91 |\n",
      "|2014|98 |\n",
      "|2015|127|\n",
      "|2016|297|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql(\"select year, count(1) as cnt from imdb_delta group by year order by year asc\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr>\n",
       "<tr><td>1</td><td>2025-08-30 17:29:40</td><td>NULL</td><td>NULL</td><td>DELETE</td><td>{predicate -&gt; [&quot;(year#3842 = 2010)&quot;]}</td><td>NULL</td><td>NULL</td><td>NULL</td><td>0</td><td>Serializable</td><td>false</td><td>{numRemovedFiles -&gt; 1, numRemovedBytes -&gt; 195473, numCopiedRows -&gt; 940, numDeletionVectorsAdded -...</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.1</td></tr>\n",
       "<tr><td>0</td><td>2025-08-30 17:13:06</td><td>NULL</td><td>NULL</td><td>CREATE OR REPLACE TABLE AS SELECT</td><td>{partitionBy -&gt; [], clusterBy -&gt; [], description -&gt; NULL, isManaged -&gt; true, properties -&gt; {}}</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>Serializable</td><td>false</td><td>{numFiles -&gt; 1, numOutputRows -&gt; 1000, numOutputBytes -&gt; 195473}</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
       "|version|          timestamp|userId|userName|                        operation|                                                                           operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|                                                                                    operationMetrics|userMetadata|                         engineInfo|\n",
       "+-------+-------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
       "|      1|2025-08-30 17:29:40|  NULL|    NULL|                           DELETE|                                                         {predicate -> [\"(year#3842 = 2010)\"]}|NULL|    NULL|     NULL|          0|  Serializable|        false|{numRemovedFiles -> 1, numRemovedBytes -> 195473, numCopiedRows -> 940, numDeletionVectorsAdded -...|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.1|\n",
       "|      0|2025-08-30 17:13:06|  NULL|    NULL|CREATE OR REPLACE TABLE AS SELECT|{partitionBy -> [], clusterBy -> [], description -> NULL, isManaged -> true, properties -> {}}|NULL|    NULL|     NULL|       NULL|  Serializable|        false|                                    {numFiles -> 1, numOutputRows -> 1000, numOutputBytes -> 195473}|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.1|\n",
       "+-------+-------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql2(\"describe history imdb_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>count</th></tr>\n",
       "<tr><td>2006</td><td>44</td></tr>\n",
       "<tr><td>2007</td><td>53</td></tr>\n",
       "<tr><td>2008</td><td>52</td></tr>\n",
       "<tr><td>2009</td><td>51</td></tr>\n",
       "<tr><td>2010</td><td>60</td></tr>\n",
       "<tr><td>2011</td><td>63</td></tr>\n",
       "<tr><td>2012</td><td>64</td></tr>\n",
       "<tr><td>2013</td><td>91</td></tr>\n",
       "<tr><td>2014</td><td>98</td></tr>\n",
       "<tr><td>2015</td><td>127</td></tr>\n",
       "<tr><td>2016</td><td>297</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+\n",
       "|year|count|\n",
       "+----+-----+\n",
       "|2006|   44|\n",
       "|2007|   53|\n",
       "|2008|   52|\n",
       "|2009|   51|\n",
       "|2010|   60|\n",
       "|2011|   63|\n",
       "|2012|   64|\n",
       "|2013|   91|\n",
       "|2014|   98|\n",
       "|2015|  127|\n",
       "|2016|  297|\n",
       "+----+-----+"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from imdb_delta version as of 0\").groupBy(\"year\").count().orderBy(asc(\"year\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>count</th></tr>\n",
       "<tr><td>2006</td><td>44</td></tr>\n",
       "<tr><td>2007</td><td>53</td></tr>\n",
       "<tr><td>2008</td><td>52</td></tr>\n",
       "<tr><td>2009</td><td>51</td></tr>\n",
       "<tr><td>2011</td><td>63</td></tr>\n",
       "<tr><td>2012</td><td>64</td></tr>\n",
       "<tr><td>2013</td><td>91</td></tr>\n",
       "<tr><td>2014</td><td>98</td></tr>\n",
       "<tr><td>2015</td><td>127</td></tr>\n",
       "<tr><td>2016</td><td>297</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+\n",
       "|year|count|\n",
       "+----+-----+\n",
       "|2006|   44|\n",
       "|2007|   53|\n",
       "|2008|   52|\n",
       "|2009|   51|\n",
       "|2011|   63|\n",
       "|2012|   64|\n",
       "|2013|   91|\n",
       "|2014|   98|\n",
       "|2015|  127|\n",
       "|2016|  297|\n",
       "+----+-----+"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from imdb_delta version as of 1\").groupBy(\"year\").count().orderBy(asc(\"year\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_2010 = tsv.where(\"year = 2010\")\n",
    "year_2010.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2010.write.format(\"delta\").mode(\"append\").saveAsTable(\"default.imdb_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|year|cnt|\n",
      "+----+---+\n",
      "|2006|44 |\n",
      "|2007|53 |\n",
      "|2008|52 |\n",
      "|2009|51 |\n",
      "|2010|60 |\n",
      "|2011|63 |\n",
      "|2012|64 |\n",
      "|2013|91 |\n",
      "|2014|98 |\n",
      "|2015|127|\n",
      "|2016|297|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select year, count(1) as cnt from imdb_delta group by year order by year asc\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr>\n",
       "<tr><td>0</td><td>2025-08-30 17:13:06</td><td>NULL</td><td>NULL</td><td>CREATE OR REPLACE TABLE AS SELECT</td><td>{partitionBy -&gt; [], clusterBy -&gt; [], description -&gt; NULL, isManaged -&gt; true, properties -&gt; {}}</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>Serializable</td><td>false</td><td>{numFiles -&gt; 1, numOutputRows -&gt; 1000, numOutputBytes -&gt; 195473}</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.1</td></tr>\n",
       "<tr><td>1</td><td>2025-08-30 17:29:40</td><td>NULL</td><td>NULL</td><td>DELETE</td><td>{predicate -&gt; [&quot;(year#3842 = 2010)&quot;]}</td><td>NULL</td><td>NULL</td><td>NULL</td><td>0</td><td>Serializable</td><td>false</td><td>{numRemovedFiles -&gt; 1, numRemovedBytes -&gt; 195473, numCopiedRows -&gt; 940, numDeletionVectorsAdded -...</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.1</td></tr>\n",
       "<tr><td>2</td><td>2025-08-30 17:47:57</td><td>NULL</td><td>NULL</td><td>WRITE</td><td>{mode -&gt; Append, partitionBy -&gt; []}</td><td>NULL</td><td>NULL</td><td>NULL</td><td>1</td><td>Serializable</td><td>true</td><td>{numFiles -&gt; 1, numOutputRows -&gt; 60, numOutputBytes -&gt; 18002}</td><td>NULL</td><td>Apache-Spark/3.5.3 Delta-Lake/3.2.1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
       "|version|          timestamp|userId|userName|                        operation|                                                                           operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|                                                                                    operationMetrics|userMetadata|                         engineInfo|\n",
       "+-------+-------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
       "|      0|2025-08-30 17:13:06|  NULL|    NULL|CREATE OR REPLACE TABLE AS SELECT|{partitionBy -> [], clusterBy -> [], description -> NULL, isManaged -> true, properties -> {}}|NULL|    NULL|     NULL|       NULL|  Serializable|        false|                                    {numFiles -> 1, numOutputRows -> 1000, numOutputBytes -> 195473}|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.1|\n",
       "|      1|2025-08-30 17:29:40|  NULL|    NULL|                           DELETE|                                                         {predicate -> [\"(year#3842 = 2010)\"]}|NULL|    NULL|     NULL|          0|  Serializable|        false|{numRemovedFiles -> 1, numRemovedBytes -> 195473, numCopiedRows -> 940, numDeletionVectorsAdded -...|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.1|\n",
       "|      2|2025-08-30 17:47:57|  NULL|    NULL|                            WRITE|                                                           {mode -> Append, partitionBy -> []}|NULL|    NULL|     NULL|          1|  Serializable|         true|                                       {numFiles -> 1, numOutputRows -> 60, numOutputBytes -> 18002}|        NULL|Apache-Spark/3.5.3 Delta-Lake/3.2.1|\n",
       "+-------+-------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------+------------+-----------------------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql(\"describe history imdb_delta\").orderBy(asc(\"version\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
