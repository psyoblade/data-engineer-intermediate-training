{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5일차 1교시 - Spark Repartition vs. Coalesce Explained\n",
    "> 스파크는 분산 환경에서 병렬 처리를 잘하는 엔진인데 여기에서 병렬처리의 단위가 파티션이며 스파크 내부 구조에 의해 관리되지만 이용자에 의해 조정되기도 합니다.\n",
    "> 그리고 스파크 어플리케이션을 수행하면서 가장 자주 많이 확인하게 되는 파티션 수에 대해 이해하고, 관련 이슈들을 어떻게 해결하는지 실습합니다.\n",
    "\n",
    "### 목차\n",
    "* 1. What is Partition ?\n",
    "* 2. Why Partition needed ?\n",
    "* 3. What is Replication ?\n",
    "* 4. What is Coalesce ?\n",
    "* 5. Which Repartition or Coalesce ?\n",
    "* 6. References\n",
    "  * [Spark Repartition & Coalesce](https://datanoon.com/blog/spark_repartition_coalesce)\n",
    "  * [Spark Repartition vs. Coalesce](https://sparkbyexamples.com/spark/spark-repartition-vs-coalesce/)\n",
    "  * https://medium.com/swlh/building-partitions-for-processing-data-files-in-apache-spark-2ca40209c9b7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/21 08:54:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from IPython.display import display, display_pretty, clear_output, JSON\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.sql.session.timeZone\", \"Asia/Seoul\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# 노트북에서 테이블 형태로 데이터 프레임 출력을 위한 설정을 합니다\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # display enabled\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 100) # display output columns size\n",
    "\n",
    "# 공통 데이터 위치\n",
    "home_jovyan = \"/home/jovyan\"\n",
    "work_data = f\"{home_jovyan}/work/data\"\n",
    "work_dir=!pwd\n",
    "work_dir = work_dir[0]\n",
    "\n",
    "# 로컬 환경 최적화\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5) # the number of partitions to use when shuffling data for joins or aggregations.\n",
    "spark.conf.set(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 'Partition'이란 무엇인가?\n",
    "> 입력 데이터의 논리적인 청크들 혹은 데이터 덩어리라고 말할수 있으며, 스파크는 이러한 파티션을 물리적으로 다른 노드에 분산 저장한다\n",
    "<br>\n",
    "\n",
    "<!-- ![docker](image/docker.png)-->\n",
    "<img src=\"images/docker.png\" width=\"300\" height=\"130\" />\n",
    "\n",
    "#### 아래와 같이 이러한 파티션 정보를 내부 Hash Partitioning Scheme 을 유지하는데 rdd.glom() 명령을 통해 확인할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.parallelize(range(1,11)).getNumPartitions() == sc.defaultParallelism == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 파티션 정보를 어떻게 확인하는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[Row(_1=1), Row(_1=2), Row(_1=3)],\n",
       " [Row(_1=4), Row(_1=5), Row(_1=6)],\n",
       " [Row(_1=7), Row(_1=8), Row(_1=9), Row(_1=10)]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parallelize 함수를 통해 rdd 생성\n",
    "rdd = sc.parallelize(range(1, 11))\n",
    "rdd.getNumPartitions()\n",
    "\n",
    "# RDD 의 경우 파티션 정보를 확인\n",
    "rdd.glom().collect()\n",
    "\n",
    "# Dataframe 의 경우 파티션 정보를 확인\n",
    "df = rdd.map(lambda x: (x, )).toDF()\n",
    "df.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 파티션 수는 어떻게 결정나는가?\n",
    "> 임의의 파일을 읽어서 데이터 프레임을 생성할 수도 있는데 이 때에 Hadoop2 기본 블록 사이즈가 128mb 이므로 약 1gb 데이터를 읽어들일 때에 약 10개의 파티션이 생성될 수 있으므로 파일이 128mb 보다 작은 경우는 1개의 파티션으로 읽어들일 것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 'Partition'은 왜 필요한가?\n",
    "> 파일을 읽을 때부터 파티션을 결정할 수 있으며, 한 번에 수행할 수 있는 Executor 수를 결정짓기 때문에 병렬성을 결정 짓는 가장 큰 요소입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numOfPartition = 1\n",
    "rdd = sc.parallelize(range(10), numOfPartition)\n",
    "rdd.collect() # Use rdd.glom().collect() instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 'Replication' 무엇인가?\n",
    "> 이미 생성된 파티션의 크기를 임의로 저장하는 명령이며 hash partitioned 된 데이터 파티션을 생성하며 모든 파티션은 동일한 크기를 가집니다.\n",
    "\n",
    "#### 3.1 컬럼 지정을 통해 파티션을 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(1, 100)\n",
    "ds = df.repartition(\"id\") # 기본 키로 id 컬럼이 생성됩니다\n",
    "ds.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 위의 repartition 시에는 shuffle 이 발생하기 때문에 결과는 spark.sql.shuffle.partitions 값에 의해 파티션 수가 결정되므로 아래의 값을 확인합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.shuffle.partitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 직접 파티션 수를 지정하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(3).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 'Coalesce'는 무엇인가?\n",
    "> 데이터프레임에 포함된 파티션의 수를 줄이는 명령입니다. 파티션 수는 절대 늘어날 수 없고 줄일 수만 있으며, 리파티션과 다르게 셔플이 발생하지 않으며, 각 파티션이 균등하게 분포된다는 보장은 없습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(1, 10)\n",
    "df3 = df.repartition(3)\n",
    "df3.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(id=1), Row(id=4), Row(id=8)],\n",
       " [Row(id=3), Row(id=5), Row(id=9), Row(id=2), Row(id=6), Row(id=7)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.coalesce(2).rdd.glom().collect() # 3개의 파티션이 2개로 줄어들기 때문에 2개가 1개로 merge 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(id=1), Row(id=4), Row(id=8)],\n",
       " [Row(id=3), Row(id=5), Row(id=9)],\n",
       " [Row(id=2), Row(id=6), Row(id=7)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.coalesce(8).rdd.glom().collect() # 오류는 나지 않으나 기존 파티션 수 3개가 그대로 유지됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 'Repartition'과 'Coalesce' 중에서 언제 어떤 것을 쓰면 좋은가?\n",
    "\n",
    "#### 5.1 Repartition\n",
    "* 최종 파티션이 균등한 크기로 분포되기를 원할 때\n",
    "* 파티션 수를 늘릴 필요가 있을 때\n",
    "* 마지막 Stage 단계의 Reduce 작업이 충분히 큰 데이터 처리가 있어 병렬성을 보장 받아야 하지만, 최종 결과 데이터는 충분히 작은 파티션으로 생성되어야 하는 경우\n",
    "![repartition](images/repartition.png)\n",
    "\n",
    "#### 5.2 Coalesce\n",
    "* 셔플을 발생시키지 않고 파티션 수를 줄이려고 할 때\n",
    "* 파티션 수를 줄이기만 할 때\n",
    "* 직전 Reduce 작업에 전달되는 데이터 크기가 충분히 작아서 Coalesce(#) 크기의 병렬성을 보장 받아도 충분히 빠른 경우\n",
    "![coalesce](images/coalesce.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 비교 실습\n",
    "> 각 천만 건의 레코드를 가진 데이터프레임의 Repartition 과 Coealesce 수행 시의 차이점을 확인하고 explain 을 통해 비교합니다\n",
    "2개의 데이터 프레임을 생성하고, 1:1 조인이 되지 않도록 3의 배수, 2의 배수로 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.range(1, 3000000, 3) # 1:1 조인이 되지 않도록 3의 배수\n",
    "df2 = spark.range(1, 2000000, 2) # 2의 배수로 숫자를 생성합니다\n",
    "print(df1.rdd.getNumPartitions(), df2.rdd.getNumPartitions(), spark.conf.get(\"spark.sql.shuffle.partitions\"))\n",
    "df1.write.mode(\"overwrite\").save(\"target/troubleshoot1/df1\")\n",
    "df2.write.mode(\"overwrite\").save(\"target/troubleshoot1/df2\")\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 기본적으로 생성되는 id 컬럼을 이용하여 inner join 을 수행하고, 각각 repartition 및 coalesce 를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "df12 = df1.join(df2, \"id\")\n",
    "# df12.show()\n",
    "df12.write.mode(\"overwrite\").save(\"target/troubleshoot1/df12\")\n",
    "\n",
    "finalNumOfPartition = 1\n",
    "df3 = df12.repartition(finalNumOfPartition)\n",
    "df3.write.mode(\"overwrite\").save(\"target/troubleshoot1/df3\")\n",
    "df4 = df12.coalesce(finalNumOfPartition)\n",
    "df4.write.mode(\"overwrite\").save(\"target/troubleshoot1/df4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumPartitions(items):\n",
    "    for item in items:\n",
    "        print(item.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "getNumPartitions([df1.rdd, df2.rdd, df12.rdd, df3.rdd, df4.rdd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 각 데이터 프레임의 파티션 수는 도커와 같은 컨테이너 환경에서 모든 리소스 매니저를 운영하기에 전체 코어 수에 바운드됩니다. 하지만 아래와 같이 파일로 저장한 이후에 다시 해당 파티션을 읽어오는 경우는 저장시의 파티션 수를 반드시 따르지는 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "rdd1 = spark.sparkContext.textFile(\"target/troubleshoot1/df1\")\n",
    "rdd2 = spark.sparkContext.textFile(\"target/troubleshoot1/df2\")\n",
    "rdd12 = spark.sparkContext.textFile(\"target/troubleshoot1/df12\")\n",
    "rdd3 = spark.sparkContext.textFile(\"target/troubleshoot1/df3\")\n",
    "rdd4 = spark.sparkContext.textFile(\"target/troubleshoot1/df4\")\n",
    "\n",
    "getNumPartitions([rdd1, rdd2, rdd12, rdd3, rdd4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 아래의 기본 설정에 따라 파티션을 읽고 쓸 때에 스파크 엔진에서 최적화를 수행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "defaultShufflePartitions: 5\n",
      "defaultMinPartitions: 2\n",
      "defaultParallelism: 3\n",
      "maxPartitionBytes: 128mb\n",
      "openCostInBytes: 4mb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "defaultShufflePartitions = int(spark.conf.get(\"spark.sql.shuffle.partitions\"))\n",
    "defaultMinPartitions = sc.defaultMinPartitions\n",
    "defaultParallelism = sc.defaultParallelism\n",
    "defaultMaxPartitionBytes = int(spark.conf.get(\"spark.sql.files.maxPartitionBytes\").replace(\"b\", \"\"))\n",
    "defaultOpenCostInBytes = int(spark.conf.get(\"spark.sql.files.openCostInBytes\"))\n",
    "out = \"\"\"\n",
    "defaultShufflePartitions: %d\n",
    "defaultMinPartitions: %d\n",
    "defaultParallelism: %d\n",
    "maxPartitionBytes: %dmb\n",
    "openCostInBytes: %dmb\n",
    "\"\"\" % (defaultShufflePartitions, defaultMinPartitions, defaultParallelism, \n",
    "       defaultMaxPartitionBytes/(1024*1024), defaultOpenCostInBytes/(1024*1024))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.sql.session.timeZone', 'Asia/Seoul'),\n",
       " ('spark.driver.host', '36066668d2b9'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.port', '41917'),\n",
       " ('spark.app.name', 'pyspark-shell'),\n",
       " ('spark.driver.extraJavaOptions',\n",
       "  '-Dio.netty.tryReflectionSetAccessible=true'),\n",
       " ('spark.app.startTime', '1629536052159'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/home/jovyan/work/lgde-spark-troubleshoot/spark-warehouse'),\n",
       " ('spark.app.id', 'local-1629536053248'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-Dio.netty.tryReflectionSetAccessible=true'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 개별 데이터 프레임 Repartition 의 경우 이전 Join Stage 가 완료된 이후에 별도의 Stage 로 Exchange (shuffle) 후에 RoundRobinPartition \n",
    "http://localhost:4040/SQL/ 페이지를 통해 확인할 수 있으며, 조인 단계에서 200개의 병렬성을 그대로 활용할 수 있습니다.\n",
    "\n",
    "![repartition](images/repartition.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Repartition 1, true\n",
      "+- Project [id#16L]\n",
      "   +- Join Inner, (id#16L = id#18L)\n",
      "      :- Range (1, 3000000, step=3, splits=Some(3))\n",
      "      +- Range (1, 2000000, step=2, splits=Some(3))\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "id: bigint\n",
      "Repartition 1, true\n",
      "+- Project [id#16L]\n",
      "   +- Join Inner, (id#16L = id#18L)\n",
      "      :- Range (1, 3000000, step=3, splits=Some(3))\n",
      "      +- Range (1, 2000000, step=2, splits=Some(3))\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Repartition 1, true\n",
      "+- Project [id#16L]\n",
      "   +- Join Inner, (id#16L = id#18L)\n",
      "      :- Range (1, 3000000, step=3, splits=Some(3))\n",
      "      +- Range (1, 2000000, step=2, splits=Some(3))\n",
      "\n",
      "== Physical Plan ==\n",
      "Exchange RoundRobinPartitioning(1), REPARTITION_WITH_NUM, [id=#317]\n",
      "+- *(2) Project [id#16L]\n",
      "   +- *(2) BroadcastHashJoin [id#16L], [id#18L], Inner, BuildRight, false\n",
      "      :- *(2) Range (1, 3000000, step=3, splits=3)\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [id=#312]\n",
      "         +- *(1) Range (1, 2000000, step=2, splits=3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, \"id\").repartition(1).explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 반면에 Coealesce 의 경우는 이전 Stage 인 Join 자체가 제한된 Reduce 작업을 통해 수행됩니다.\n",
    "![coalesce](images/coalesce.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Repartition 1, false\n",
      "+- Project [id#16L]\n",
      "   +- Join Inner, (id#16L = id#18L)\n",
      "      :- Range (1, 3000000, step=3, splits=Some(3))\n",
      "      +- Range (1, 2000000, step=2, splits=Some(3))\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "id: bigint\n",
      "Repartition 1, false\n",
      "+- Project [id#16L]\n",
      "   +- Join Inner, (id#16L = id#18L)\n",
      "      :- Range (1, 3000000, step=3, splits=Some(3))\n",
      "      +- Range (1, 2000000, step=2, splits=Some(3))\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Repartition 1, false\n",
      "+- Project [id#16L]\n",
      "   +- Join Inner, (id#16L = id#18L)\n",
      "      :- Range (1, 3000000, step=3, splits=Some(3))\n",
      "      +- Range (1, 2000000, step=2, splits=Some(3))\n",
      "\n",
      "== Physical Plan ==\n",
      "Coalesce 1\n",
      "+- *(2) Project [id#16L]\n",
      "   +- *(2) BroadcastHashJoin [id#16L], [id#18L], Inner, BuildRight, false\n",
      "      :- *(2) Range (1, 3000000, step=3, splits=3)\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [id=#353]\n",
      "         +- *(1) Range (1, 2000000, step=2, splits=3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, \"id\").coalesce(1).explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 실제 동일한 조인 연산을 수행할 때에 Repartition 과 Coalesce 가 성능에 어느정도 영향을 미치는지 확인해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 ms, sys: 1.34 ms, total: 2.94 ms\n",
      "Wall time: 957 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df3.write.mode(\"overwrite\").format(\"csv\").save(\"target/troubleshoot1/repartition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 397 µs, sys: 1.89 ms, total: 2.29 ms\n",
      "Wall time: 627 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df4.write.mode(\"overwrite\").format(\"csv\").save(\"target/troubleshoot1/coalesce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
